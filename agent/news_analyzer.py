"""
í¬íŠ¸í´ë¦¬ì˜¤ ë‰´ìŠ¤ ë¶„ì„ ëª¨ë“ˆ

í¬íŠ¸í´ë¦¬ì˜¤ì— í¬í•¨ëœ ì£¼ì‹ë“¤ì˜ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import asyncio
import aiohttp
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import logging
from dataclasses import dataclass
import json
import time

# OpenAI API
import openai
from config.setting import API_CONFIG

# OpenAI API í‚¤ ì„¤ì •
OPENAI_API_KEY = API_CONFIG["OPENAI"]["ACCESS_KEY"]

logger = logging.getLogger(__name__)

@dataclass
class NewsItem:
    """ë‰´ìŠ¤ ì•„ì´í…œ ë°ì´í„° í´ë˜ìŠ¤"""
    title: str
    content: str
    source: str
    published_at: datetime
    stock_code: str
    stock_name: str
    sentiment: Optional[str] = None
    impact_score: Optional[float] = None
    summary: Optional[str] = None

@dataclass
class PortfolioNewsAnalysis:
    """í¬íŠ¸í´ë¦¬ì˜¤ ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼"""
    stock_code: str
    stock_name: str
    news_count: int
    positive_news: int
    negative_news: int
    neutral_news: int
    overall_sentiment: str
    key_insights: List[str]
    investment_recommendation: str
    risk_level: str
    last_updated: datetime

class PortfolioNewsAnalyzer:
    """í¬íŠ¸í´ë¦¬ì˜¤ ë‰´ìŠ¤ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)
        self.news_cache = {}
        self.analysis_cache = {}
        self.cache_ttl = 300  # 5ë¶„ ìºì‹œ
        
    async def fetch_stock_news(self, stock_code: str, stock_name: str, days: int = 7) -> List[NewsItem]:
        """ì£¼ì‹ë³„ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            # ì‹¤ì œ ë‰´ìŠ¤ API ëŒ€ì‹  ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì‚¬ìš©
            news_items = await self._simulate_news_fetch(stock_code, stock_name, days)
            return news_items
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ ({stock_code}): {e}")
            return []
    
    async def _simulate_news_fetch(self, stock_code: str, stock_name: str, days: int) -> List[NewsItem]:
        """ë‰´ìŠ¤ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜"""
        await asyncio.sleep(0.1)  # API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
        
        # ì£¼ì‹ë³„ ë‰´ìŠ¤ í…œí”Œë¦¿
        news_templates = {
            '005930': [  # ì‚¼ì„±ì „ì
                {
                    'title': f"{stock_name} ì‹¤ì  ê°œì„  ê¸°ëŒ€ê° í™•ì‚°",
                    'content': f"{stock_name}ì˜ ìµœê·¼ ì‹¤ì  ë°œí‘œì—ì„œ ì˜ˆìƒë³´ë‹¤ ë†’ì€ ë§¤ì¶œ ì„±ì¥ì„ ê¸°ë¡í–ˆë‹¤. ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ìˆ˜ìš” ì¦ê°€ì™€ ìŠ¤ë§ˆíŠ¸í° íŒë§¤ í˜¸ì¡°ê°€ ì£¼ìš” ì›ì¸ìœ¼ë¡œ ë¶„ì„ëœë‹¤.",
                    'sentiment': 'positive'
                },
                {
                    'title': f"{stock_name} ì‹ ê¸°ìˆ  ê°œë°œ íˆ¬ì í™•ëŒ€",
                    'content': f"{stock_name}ì´ AI ë°˜ë„ì²´ ë¶„ì•¼ì— ëŒ€ê·œëª¨ íˆ¬ìë¥¼ í™•ì •í–ˆë‹¤. í–¥í›„ 3ë…„ê°„ 50ì¡°ì› ê·œëª¨ì˜ íˆ¬ì ê³„íšì„ ë°œí‘œí–ˆë‹¤.",
                    'sentiment': 'positive'
                },
                {
                    'title': f"{stock_name} ê¸€ë¡œë²Œ ê²½ìŸ ì‹¬í™”",
                    'content': f"ì¤‘êµ­ ë°˜ë„ì²´ ì—…ì²´ë“¤ì˜ ê¸°ìˆ  ë°œì „ìœ¼ë¡œ {stock_name}ì˜ ì‹œì¥ ì ìœ ìœ¨ì— ëŒ€í•œ ìš°ë ¤ê°€ ì œê¸°ë˜ê³  ìˆë‹¤.",
                    'sentiment': 'negative'
                }
            ],
            '000660': [  # SKí•˜ì´ë‹‰ìŠ¤
                {
                    'title': f"{stock_name} ë©”ëª¨ë¦¬ ê°€ê²© ìƒìŠ¹ì„¸ ì§€ì†",
                    'content': f"{stock_name}ì˜ ì£¼ìš” ì œí’ˆì¸ DRAMê³¼ NAND ê°€ê²©ì´ ì§€ì†ì ìœ¼ë¡œ ìƒìŠ¹í•˜ê³  ìˆì–´ ì‹¤ì  ê°œì„ ì´ ì˜ˆìƒëœë‹¤.",
                    'sentiment': 'positive'
                },
                {
                    'title': f"{stock_name} HBM ê¸°ìˆ  ì„ ë„",
                    'content': f"{stock_name}ì´ ê³ ëŒ€ì—­í­ ë©”ëª¨ë¦¬(HBM) ê¸°ìˆ ì—ì„œ ê¸€ë¡œë²Œ ì„ ë„ì  ìœ„ì¹˜ë¥¼ í™•ë³´í–ˆë‹¤.",
                    'sentiment': 'positive'
                },
                {
                    'title': f"{stock_name} ì›ìì¬ ê°€ê²© ìƒìŠ¹ ì˜í–¥",
                    'content': f"ì‹¤ë¦¬ì½˜ ì›¨ì´í¼ ë“± ì›ìì¬ ê°€ê²© ìƒìŠ¹ìœ¼ë¡œ {stock_name}ì˜ ì›ê°€ ë¶€ë‹´ì´ ì¦ê°€í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.",
                    'sentiment': 'negative'
                }
            ]
        }
        
        # ê¸°ë³¸ ë‰´ìŠ¤ í…œí”Œë¦¿
        default_news = [
            {
                'title': f"{stock_name} ì‹œì¥ ë™í–¥ ë¶„ì„",
                'content': f"{stock_name}ì˜ ìµœê·¼ ì£¼ê°€ ë™í–¥ê³¼ ì‹œì¥ ì „ë§ì— ëŒ€í•œ ë¶„ì„ì´ ë‚˜ì™”ë‹¤.",
                'sentiment': 'neutral'
            }
        ]
        
        templates = news_templates.get(stock_code, default_news)
        news_items = []
        
        for i, template in enumerate(templates):
            # ë‚ ì§œ ìƒì„± (ìµœê·¼ daysì¼ ë‚´)
            days_ago = days - i
            if days_ago < 0:
                days_ago = 0
            published_at = datetime.now() - timedelta(days=days_ago)
            
            news_item = NewsItem(
                title=template['title'],
                content=template['content'],
                source=f"ë‰´ìŠ¤{i+1}",
                published_at=published_at,
                stock_code=stock_code,
                stock_name=stock_name,
                sentiment=template['sentiment']
            )
            news_items.append(news_item)
        
        return news_items
    
    async def analyze_news_sentiment(self, news_items: List[NewsItem]) -> List[NewsItem]:
        """ë‰´ìŠ¤ ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        try:
            for news_item in news_items:
                if not news_item.sentiment:
                    # OpenAI API í‚¤ í™•ì¸
                    api_key = self.openai_client.api_key
                    if (not api_key or 
                        api_key == "your openai accesskey" or 
                        "your" in api_key.lower()):
                        # ì˜¤í”„ë¼ì¸ ê°ì • ë¶„ì„ (í‚¤ì›Œë“œ ê¸°ë°˜)
                        sentiment = self._analyze_sentiment_offline(news_item.content)
                        news_item.sentiment = sentiment
                        
                        # ì˜í–¥ë„ ì ìˆ˜ ê³„ì‚°
                        news_item.impact_score = self._calculate_impact_score(news_item)
                        
                        # ìš”ì•½ ìƒì„±
                        news_item.summary = self._generate_summary_offline(news_item.content)
                    else:
                        # OpenAIë¥¼ ì‚¬ìš©í•œ ê°ì • ë¶„ì„
                        sentiment = await self._analyze_sentiment_with_openai(news_item.content)
                        news_item.sentiment = sentiment
                        
                        # ì˜í–¥ë„ ì ìˆ˜ ê³„ì‚°
                        news_item.impact_score = self._calculate_impact_score(news_item)
                        
                        # ìš”ì•½ ìƒì„±
                        news_item.summary = await self._generate_summary(news_item.content)
            
            return news_items
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            return news_items
    
    async def _analyze_sentiment_with_openai(self, content: str) -> str:
        """OpenAIë¥¼ ì‚¬ìš©í•œ ê°ì • ë¶„ì„"""
        try:
            # API í‚¤ ìƒíƒœ ë¡œê¹…
            api_key = self.openai_client.api_key
            logger.info(f"ğŸ”‘ ë‰´ìŠ¤ ê°ì • ë¶„ì„ - OpenAI API í‚¤ ìƒíƒœ:")
            logger.info(f"   - API í‚¤ ì¡´ì¬: {bool(api_key)}")
            logger.info(f"   - API í‚¤ ê¸¸ì´: {len(api_key) if api_key else 0}")
            
            # API í˜¸ì¶œ ë¡œê¹…
            logger.info(f"ğŸ“° ë‰´ìŠ¤ ê°ì • ë¶„ì„ API í˜¸ì¶œ:")
            logger.info(f"   - ë‰´ìŠ¤ ë‚´ìš©: {content[:100]}{'...' if len(content) > 100 else ''}")
            logger.info(f"   - ëª¨ë¸: gpt-3.5-turbo")
            logger.info(f"   - ìµœëŒ€ í† í°: 10")
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "ì£¼ì‹ íˆ¬ì ê´€ì ì—ì„œ ë‰´ìŠ¤ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. positive, negative, neutral ì¤‘ í•˜ë‚˜ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": f"ë‹¤ìŒ ë‰´ìŠ¤ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: {content[:500]}"
                    }
                ],
                max_tokens=10,
                temperature=0.1
            )
            
            sentiment = response.choices[0].message.content.strip().lower()
            logger.info(f"âœ… ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì™„ë£Œ: {sentiment}")
            
            if sentiment in ['positive', 'negative', 'neutral']:
                return sentiment
            else:
                logger.warning(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ê°ì • ë¶„ì„ ê²°ê³¼: {sentiment}, neutralë¡œ ì²˜ë¦¬")
                return 'neutral'
                
        except Exception as e:
            logger.error(f"âŒ OpenAI ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            return 'neutral'
    
    def _calculate_impact_score(self, news_item: NewsItem) -> float:
        """ë‰´ìŠ¤ ì˜í–¥ë„ ì ìˆ˜ ê³„ì‚°"""
        base_score = 0.5
        
        # ì œëª© ê¸¸ì´ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
        title_length = len(news_item.title)
        if title_length > 50:
            base_score += 0.2
        elif title_length > 30:
            base_score += 0.1
        
        # ë‚´ìš© ê¸¸ì´ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
        content_length = len(news_item.content)
        if content_length > 200:
            base_score += 0.2
        elif content_length > 100:
            base_score += 0.1
        
        # ê°ì •ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
        if news_item.sentiment == 'positive':
            base_score += 0.1
        elif news_item.sentiment == 'negative':
            base_score += 0.15  # ë¶€ì •ì  ë‰´ìŠ¤ê°€ ë” í° ì˜í–¥
        
        return min(base_score, 1.0)
    
    async def _generate_summary(self, content: str) -> str:
        """ë‰´ìŠ¤ ìš”ì•½ ìƒì„±"""
        try:
            # API í˜¸ì¶œ ë¡œê¹…
            logger.info(f"ğŸ“‹ ë‰´ìŠ¤ ìš”ì•½ ìƒì„± API í˜¸ì¶œ:")
            logger.info(f"   - ë‰´ìŠ¤ ë‚´ìš©: {content[:100]}{'...' if len(content) > 100 else ''}")
            logger.info(f"   - ëª¨ë¸: gpt-3.5-turbo")
            logger.info(f"   - ìµœëŒ€ í† í°: 100")
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "íˆ¬ìì ê´€ì ì—ì„œ ë‰´ìŠ¤ë¥¼ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”. í•µì‹¬ í¬ì¸íŠ¸ë§Œ 2-3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": f"ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”: {content}"
                    }
                ],
                max_tokens=100,
                temperature=0.3
            )
            
            summary = response.choices[0].message.content.strip()
            logger.info(f"âœ… ë‰´ìŠ¤ ìš”ì•½ ìƒì„± ì™„ë£Œ: {summary[:100]}{'...' if len(summary) > 100 else ''}")
            
            return summary
            
        except Exception as e:
            logger.error(f"âŒ ë‰´ìŠ¤ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return content[:100] + "..."
    
    def _analyze_sentiment_offline(self, content: str) -> str:
        """ì˜¤í”„ë¼ì¸ ê°ì • ë¶„ì„ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        try:
            content_lower = content.lower()
            
            # ê¸ì • í‚¤ì›Œë“œ
            positive_keywords = ['ìƒìŠ¹', 'ì¦ê°€', 'ì„±ì¥', 'ê°œì„ ', 'í˜¸ì¡°', 'ê¸ì •', 'ê°•ì„¸', 'ëŒíŒŒ', 'ìƒí–¥', 'ë§¤ìˆ˜', 'ì‹¤ì ', 'ì´ìµ']
            # ë¶€ì • í‚¤ì›Œë“œ
            negative_keywords = ['í•˜ë½', 'ê°ì†Œ', 'ë¶€ì§„', 'ì•…í™”', 'ë¶€ì •', 'ì•½ì„¸', 'í•˜í–¥', 'ë§¤ë„', 'ë¦¬ìŠ¤í¬', 'ìœ„í—˜', 'ì†ì‹¤', 'ì‹¤ì ë¶€ì§„']
            
            positive_count = sum(1 for keyword in positive_keywords if keyword in content_lower)
            negative_count = sum(1 for keyword in negative_keywords if keyword in content_lower)
            
            if positive_count > negative_count:
                return "positive"
            elif negative_count > positive_count:
                return "negative"
            else:
                return "neutral"
                
        except Exception as e:
            logger.error(f"ì˜¤í”„ë¼ì¸ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            return "neutral"
    
    def _generate_summary_offline(self, content: str) -> str:
        """ì˜¤í”„ë¼ì¸ ìš”ì•½ ìƒì„±"""
        try:
            # ê°„ë‹¨í•œ ìš”ì•½ ë¡œì§
            if len(content) <= 100:
                return content
            
            # ì²« ë²ˆì§¸ ë¬¸ì¥ê³¼ ë§ˆì§€ë§‰ ë¬¸ì¥ì„ ì¡°í•©
            sentences = content.split('.')
            if len(sentences) >= 2:
                summary = sentences[0] + '. ' + sentences[-1] + '.'
                return summary[:150] + "..." if len(summary) > 150 else summary
            else:
                return content[:100] + "..."
                
        except Exception as e:
            logger.error(f"ì˜¤í”„ë¼ì¸ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return content[:100] + "..." if len(content) > 100 else content
    
    async def analyze_portfolio_news(self, portfolio_stocks: Dict[str, str], days: int = 7) -> List[PortfolioNewsAnalysis]:
        """í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ë‰´ìŠ¤ ë¶„ì„"""
        try:
            all_analyses = []
            
            for stock_code, stock_name in portfolio_stocks.items():
                # ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                news_items = await self.fetch_stock_news(stock_code, stock_name, days)
                
                # ê°ì • ë¶„ì„
                analyzed_news = await self.analyze_news_sentiment(news_items)
                
                # ë¶„ì„ ê²°ê³¼ ìƒì„±
                analysis = self._create_portfolio_analysis(stock_code, stock_name, analyzed_news)
                all_analyses.append(analysis)
            
            return all_analyses
            
        except Exception as e:
            logger.error(f"í¬íŠ¸í´ë¦¬ì˜¤ ë‰´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return []
    
    def _create_portfolio_analysis(self, stock_code: str, stock_name: str, news_items: List[NewsItem]) -> PortfolioNewsAnalysis:
        """í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ê²°ê³¼ ìƒì„±"""
        # ê°ì •ë³„ ë‰´ìŠ¤ ìˆ˜ ê³„ì‚°
        positive_count = len([n for n in news_items if n.sentiment == 'positive'])
        negative_count = len([n for n in news_items if n.sentiment == 'negative'])
        neutral_count = len([n for n in news_items if n.sentiment == 'neutral'])
        
        # ì „ì²´ ê°ì • ê²°ì •
        if positive_count > negative_count:
            overall_sentiment = 'positive'
        elif negative_count > positive_count:
            overall_sentiment = 'negative'
        else:
            overall_sentiment = 'neutral'
        
        # í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        key_insights = self._generate_key_insights(news_items)
        
        # íˆ¬ì ì¶”ì²œ ìƒì„±
        investment_recommendation = self._generate_investment_recommendation(
            overall_sentiment, positive_count, negative_count, news_items
        )
        
        # ë¦¬ìŠ¤í¬ ë ˆë²¨ ê²°ì •
        risk_level = self._determine_risk_level(negative_count, len(news_items))
        
        return PortfolioNewsAnalysis(
            stock_code=stock_code,
            stock_name=stock_name,
            news_count=len(news_items),
            positive_news=positive_count,
            negative_news=negative_count,
            neutral_news=neutral_count,
            overall_sentiment=overall_sentiment,
            key_insights=key_insights,
            investment_recommendation=investment_recommendation,
            risk_level=risk_level,
            last_updated=datetime.now()
        )
    
    def _generate_key_insights(self, news_items: List[NewsItem]) -> List[str]:
        """í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []
        
        # ê¸ì •ì  ë‰´ìŠ¤ì—ì„œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        positive_news = [n for n in news_items if n.sentiment == 'positive']
        if positive_news:
            insights.append(f"ê¸ì •ì  ë‰´ìŠ¤ {len(positive_news)}ê±´: ì‹¤ì  ê°œì„  ë° ì„±ì¥ ì „ë§")
        
        # ë¶€ì •ì  ë‰´ìŠ¤ì—ì„œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        negative_news = [n for n in news_items if n.sentiment == 'negative']
        if negative_news:
            insights.append(f"ë¶€ì •ì  ë‰´ìŠ¤ {len(negative_news)}ê±´: ë¦¬ìŠ¤í¬ ìš”ì¸ ì£¼ì˜ í•„ìš”")
        
        # ë†’ì€ ì˜í–¥ë„ ë‰´ìŠ¤ì—ì„œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        high_impact_news = [n for n in news_items if n.impact_score and n.impact_score > 0.7]
        if high_impact_news:
            insights.append(f"ë†’ì€ ì˜í–¥ë„ ë‰´ìŠ¤ {len(high_impact_news)}ê±´: ì‹œì¥ ë³€ë™ì„± ì˜ˆìƒ")
        
        return insights[:3]  # ìµœëŒ€ 3ê°œ ì¸ì‚¬ì´íŠ¸
    
    def _generate_investment_recommendation(self, sentiment: str, positive: int, negative: int, news_items: List[NewsItem]) -> str:
        """íˆ¬ì ì¶”ì²œ ìƒì„±"""
        if sentiment == 'positive':
            if positive >= 3:
                return "ê°•ë ¥ ë§¤ìˆ˜ ì¶”ì²œ - ê¸ì •ì  ë‰´ìŠ¤ê°€ ì§€ì†ì ìœ¼ë¡œ ë‚˜ì˜¤ê³  ìˆìŒ"
            else:
                return "ë§¤ìˆ˜ ê³ ë ¤ - ê¸ì •ì  ì „ë§ì´ ìš°ì„¸í•¨"
        elif sentiment == 'negative':
            if negative >= 3:
                return "ë§¤ë„ ê³ ë ¤ - ë¶€ì •ì  ë‰´ìŠ¤ê°€ ì§€ì†ë˜ê³  ìˆìŒ"
            else:
                return "ê´€ë§ - ë¶€ì •ì  ìš”ì¸ ì£¼ì˜ í•„ìš”"
        else:
            return "ì¤‘ë¦½ - ëšœë ·í•œ ë°©í–¥ì„± ì—†ìŒ"
    
    def _determine_risk_level(self, negative_count: int, total_count: int) -> str:
        """ë¦¬ìŠ¤í¬ ë ˆë²¨ ê²°ì •"""
        if total_count == 0:
            return "ë‚®ìŒ"
        
        negative_ratio = negative_count / total_count
        
        if negative_ratio >= 0.6:
            return "ë†’ìŒ"
        elif negative_ratio >= 0.3:
            return "ë³´í†µ"
        else:
            return "ë‚®ìŒ"
    
    async def get_real_time_news_feed(self, portfolio_stocks: Dict[str, str]) -> List[NewsItem]:
        """ì‹¤ì‹œê°„ ë‰´ìŠ¤ í”¼ë“œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            all_news = []
            
            for stock_code, stock_name in portfolio_stocks.items():
                # ìµœê·¼ 1ì¼ ë‰´ìŠ¤ë§Œ ê°€ì ¸ì˜¤ê¸°
                news_items = await self.fetch_stock_news(stock_code, stock_name, days=1)
                all_news.extend(news_items)
            
            # ì‹œê°„ìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)
            all_news.sort(key=lambda x: x.published_at, reverse=True)
            
            return all_news[:20]  # ìµœì‹  20ê°œ ë‰´ìŠ¤ë§Œ ë°˜í™˜
            
        except Exception as e:
            logger.error(f"ì‹¤ì‹œê°„ ë‰´ìŠ¤ í”¼ë“œ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return []

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
news_analyzer = PortfolioNewsAnalyzer()
